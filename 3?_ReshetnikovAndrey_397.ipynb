{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Машинное обучение</center>\n",
    "<center><small>Домашнее задание 3</small></center>\n",
    "<center><i>Решетников Андрей, 397 группа</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При жадном обучении решающих деревьев на каждом шаге выбирается разбиение, максимизирующее величину:\n",
    "$$ \\Delta = F(X, Y) - \\frac{(X_1,Y_1)}{(X, Y)}\\cdot H(X_1, Y_1) - \\frac{(X_2, Y_2)}{(X, Y)} \\cdot H(X_2, Y_2) $$\n",
    "где $(X,Y)$ выборка в исходной вершине, где $(X_1,Y_1)$, $(X_2,Y_2)$ - выборки в вершинах-потомках, а функция $H(X,Y)$ - некоторая мера неоднородности выборки $(X,Y)$\n",
    "\n",
    "Общепринятыми функциями являются:\n",
    " $$ 1.\\ H(X, Y) = - \\sum_{y_i\\in Y}p_{y_i}\\log(p_{y_i}) - энтропия$$ \n",
    " $$ 2.\\ H(X, Y) = 1 - \\sum_{y_i\\in Y}p_{y_i}^2 - индекс Джини$$ \n",
    " $$ 3.\\ H(X, Y) = 1 - \\max {p_{y_i}} - вероятность ошибочной классификации$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def entropy(x):\n",
    "    chance = [value / sum(x) for value in x]\n",
    "    return sum(-p * log2(p) for p in chance)\n",
    "\n",
    "def giney_index(x):\n",
    "    chance = [value / sum(x) for value in x]\n",
    "    return 1 - sum(p ** 2 for p in chance)\n",
    "\n",
    "def chance_error_classification(x):\n",
    "    chance = [value / sum(x) for value in x]\n",
    "    return 1 - max(chance)\n",
    "\n",
    "def delta(x, y, func):\n",
    "    S1 = sum(x)\n",
    "    S2 = sum(y)\n",
    "    S = S1 + S2\n",
    "    return - S1 / S * func(x) - S2 / S * func(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "На первом шаге из 3 случаев, у нас всего 2 варианта разбиения\n",
    "\n",
    "Для энтропии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.33333333333 -1.25162916739\n"
     ]
    }
   ],
   "source": [
    "print(delta([200], [100, 100, 100, 100], entropy), delta([200, 100], [100, 100, 100], entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс Джини:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5 -0.555555555556\n"
     ]
    }
   ],
   "source": [
    "print(delta([200], [100, 100, 100, 100], giney_index), delta([200, 100], [100, 100, 100], giney_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность ошибочной классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5 -0.5\n"
     ]
    }
   ],
   "source": [
    "print(delta([200], [100, 100, 100, 100], chance_error_classification), delta([200, 100], [100, 100, 100], chance_error_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что случай с энтропией лучше для второго разбиения, значит картинка 3 относится к энтропии\n",
    "Проделаем то же самое для второго шага, для разбиений [100, 50, 50]:[50, 50, 100] и [95, 80, 20, 5]:[5, 20, 80, 95]\n",
    "\n",
    "Индекс Джини:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.625 -0.60375\n"
     ]
    }
   ],
   "source": [
    "print(delta([100, 50, 50], [50, 50, 100], giney_index), delta([95, 80, 20, 5], [5, 20, 80, 95], giney_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность ошибочной классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5 -0.525\n"
     ]
    }
   ],
   "source": [
    "print(delta([100, 50, 50], [50, 50, 100], chance_error_classification), delta([95, 80, 20, 5], [5, 20, 80, 95], chance_error_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге индекс Джини - второе разбиение, ошибочная классификация - первое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдокод с семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGA with only mutations --> Stochastic Search (T mutations over individual)\\nB=1 --> Stochastic Local Search\\n\\nAdaptation (idea): to increase probability of good features and to decrease probability of bad ones.\\n\\nAlgorithm:\\n1. p_1 = .. = p_n = 1 / n (feature uniform distribution)\\n2. for j in j_0 .. n: (feature set size)\\n3.     for t in 1..T: (iteration count)\\n4.         F_j = generate r feature sets of size j based on (p_1,...,p_n) distribution\\n5.         F_worse = argmax_{S \\\\in F_j} Q(S) (worse)\\n           F_best = argmax_{S \\\\in F_j} Q(S) (best)\\n6.         H = 0 (delta)\\n           for f_i in F_worse:\\n               p_delta = min(p_i, h)\\n               p_i -= p_delta\\n               H += p_delta\\n           for f_i in F_best:\\n               p_i += H / j\\n7.      j* = argmin_{s <= j} Q(F_s)\\n8.      if j - j* >= d:\\n            return F_j*\\n\\nDegrees of freedom:\\n* r (level of significance 0.05 -> 39, 0.1 -> 19. Analogy with ShuffleSplit)\\n* T (iteration count: 10-50)\\n* h (degree of adaptation: try to skip zero probabilities, e.g. (1 - p_min) / rn)\\n\\nPro:\\n* Should be better than AddDel (in quality)\\n* Convergence speeds up with adaptation\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "GA with only mutations --> Stochastic Search (T mutations over individual)\n",
    "B=1 --> Stochastic Local Search\n",
    "\n",
    "Adaptation (idea): to increase probability of good features and to decrease probability of bad ones.\n",
    "\n",
    "Algorithm:\n",
    "1. p_1 = .. = p_n = 1 / n (feature uniform distribution)\n",
    "2. for j in j_0 .. n: (feature set size)\n",
    "3.     for t in 1..T: (iteration count)\n",
    "4.         F_j = generate r feature sets of size j based on (p_1,...,p_n) distribution\n",
    "5.         F_worse = argmax_{S \\in F_j} Q(S) (worse)\n",
    "           F_best = argmax_{S \\in F_j} Q(S) (best)\n",
    "6.         H = 0 (delta)\n",
    "           for f_i in F_worse:\n",
    "               p_delta = min(p_i, h)\n",
    "               p_i -= p_delta\n",
    "               H += p_delta\n",
    "           for f_i in F_best:\n",
    "               p_i += H / j\n",
    "7.      j* = argmin_{s <= j} Q(F_s)\n",
    "8.      if j - j* >= d:\n",
    "            return F_j*\n",
    "\n",
    "Degrees of freedom:\n",
    "* r (level of significance 0.05 -> 39, 0.1 -> 19. Analogy with ShuffleSplit)\n",
    "* T (iteration count: 10-50)\n",
    "* h (degree of adaptation: try to skip zero probabilities, e.g. (1 - p_min) / rn)\n",
    "\n",
    "Pro:\n",
    "* Should be better than AddDel (in quality)\n",
    "* Convergence speeds up with adaptation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def SLS(estimator, X_train, Y_train, X_test, Y_test, r, T, h, d):\n",
    "    global_current_best_score = 0 \n",
    "    global_current_best_set = []\n",
    "    n = X_train.shape[1] \n",
    "    p = [1 / n] * n \n",
    "    non_change = 0\n",
    "    for index_j in range(1, n + 1):\n",
    "        local_current_best_set = []\n",
    "        local_current_best_score = 0\n",
    "        for index_t in range(T):\n",
    "            variates = [np.random.choice(n, index_j, replace = False, p = p) for q in range(r)]\n",
    "            min_current_score = 1\n",
    "            max_current_score = 0\n",
    "            feature_set_best = []\n",
    "            feature_set_worst = []\n",
    "            for feature_set in variates:\n",
    "                estimator.fit(X_train[:, feature_set], Y_train)\n",
    "                result = estimator.score(X_test[:, feature_set], Y_test)\n",
    "                if result > max_current_score:\n",
    "                    max_current_score = result\n",
    "                    feature_set_best = feature_set\n",
    "                if result < min_current_score:\n",
    "                    min_current_score = result\n",
    "                    feature_set_worst = feature_set\n",
    "                if result > local_current_best_score:\n",
    "                    local_current_best_score = result\n",
    "                    local_current_best_set = feature_set\n",
    "            delta_H = 0 \n",
    "            for bad_feature in feature_set_worst:\n",
    "                p_delta = min(p[bad_feature], h)\n",
    "                p[bad_feature] -= p_delta\n",
    "                delta_H += p_delta\n",
    "            for good_feature in feature_set_best:\n",
    "                p[good_feature] += delta_H / index_j\n",
    "        estimator.fit(X_train[:, local_current_best_set], Y_train)\n",
    "        current_score = estimator.score(X_test[:, local_current_best_set], Y_test)\n",
    "        if current_score > global_current_best_score:\n",
    "            global_current_best_score = current_score\n",
    "            global_current_best_set = local_current_best_set\n",
    "            non_change = 0\n",
    "        else:\n",
    "            non_change += 1\n",
    "        if non_change >= d:\n",
    "            break;\n",
    "    return global_current_best_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "data= read_csv('/Users/Hoderu/Downloads/train.csv')[:1500]\n",
    "train = data[:500]\n",
    "test = data[500:1000]\n",
    "X_train = np.asarray(train[list(range(1, 785))])\n",
    "Y_train = np.asarray(train['label'])\n",
    "X_test = np.asarray(test[list(range(1, 785))])\n",
    "Y_test = np.asarray(test['label'])\n",
    "X_control = np.asarray(test[list(range(1, 785))])\n",
    "Y_control = np.asarray(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimator = KNeighborsClassifier(algorithm='ball_tree')\n",
    "selected_features = SLS(estimator, X_train, Y_train, X_test, Y_test, r=19, T=10, h=1/16000, d=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114258048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pylab\n",
    "\n",
    "to_plot = np.asarray([0] * 784)\n",
    "to_plot[selected_features] = 255\n",
    "pylab.imshow(to_plot.reshape(28, 28), cmap='winter')\n",
    "estimator.fit(X_test[:, selected_features], Y_test)\n",
    "print(estimator.score(X_control[:, selected_features], Y_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество распознавания 87,4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
